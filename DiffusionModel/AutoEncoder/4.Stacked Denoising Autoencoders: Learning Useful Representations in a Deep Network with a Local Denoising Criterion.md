**논문 요약**
이 논문에서는 "Stacked Denoising Autoencoders"라는 개념을 제안하고, 이를 사용하여 깊은 신경망에서 효과적인 표현을 학습하는 방법을 탐구합니다.
오토인코더는 입력 데이터를 저차원 코드로 변환하고 다시 복원하는데 사용되는 모델로, 이 논문에서는 노이즈 제거 오토인코더를 사용하여 신경망의 각 층을 순차적으로 학습하는 방법을 제시합니다.

**1.노이즈 제거 오토인코더** : 오토인코더는 입력 데이터를 저차원의 표현으로 압축하고 다시 복원하는 신경망 기반의 모델
노이즈 제거 오토인코더는 오토인코더의 변형 중 하나로, 학습할 때 입력 데이터에 노이즈를 추가하여 노이즈에 강건한 표현을 학습하는 방식
이렇게 함으로써 오토인코더는 입력 데이터의 잡음이나 변형에 더 강한 특징을 학습하게 됩니다.
- 오토인코더 : 입력데이터를 저차원의 표현으로 압축한다음 다시 원본데이터를 복원하는 신경망 기반의 모델, 이 과정을 통해 중요한 특징을 추출하거나 차원을 축소하는데 사용, 입력과 출력이 동일한 구조를 가지며, 데이터의 잠재적인 구조나 특징을 학습하여 표현
- 노이즈 제거 오토인코더 : 입력 데이터에 의도적으로 노이즈를 추가한 뒤, 원래 데이터를 복원하도록 학습, 이를 통해 노이즈나 변형된 데이터에 대해 더 강건한 표현을 학습하도록 유도
  1. 입력데이터에 노이즈를 추가하여 노이즈가 섞인 데이터 생성
  2. 생성된 노이즈가 섞인 데이터를 모델에 입력으로 주고, 원래 입력 데이터를 복원하도록 학습
  3. 모델은 원래 입력 데이터와 복원된 데이터 간의 차이를 최소화하도록 가중치를 조정하며 학습

**2.Stacked Denoising Autoencoders** : 이는 여러 개의 노이즈 제거 오토인코더를 층별로 쌓아 올리는 방법
즉, 첫 번쨰 노이즈 제거 오토인코더가 입력 데이터를 저차원 표현으로 변환하고, 다음 노이즈 제거 오토 인코더는 첫 번째 오토인코더의 저차원 표현을 더 추상화 된 표현으로 변환하며, 이런식으로 여러 층을 쌓아감
  1. 개별 노이즈 제거 오토인코더 : 먼저 각 층마다 개별적인 노이즈 제거 오토인코더를 학습 시킵니다. 첫 번째 노이즈 제거 오토인코더는 입력 데이터를 받아서 저차원 표현으로 압축하고 복원합니다. 그다음 노이즈 제거 오토인코더는 첫 번째 오토인코더의 저차원 표현을 더 추상화 된 표현으로 변환하고 다시 복원합니다. 이렇게 하나의 층마다 노이즈 제거 오토인코더를 학습시킵니다.
  2. 층별적용 : 학습된 첫 번째 노이즈 제거 오토 인코더의 저차원 표현을 입력으로 사용하여 두번 째 노이즈 제거 오토인코더를 학습합니다. 이때, 두 번째 오토인코더는 첫 번째 오토인코더의 저차원 표현을 더 추상화된 표현으로 변환하고 다시 복원하도록 학습됩니다. 이런식으로 층을 추가하면서 계속해서 더 의미 있는 표현을 학습호도록 합니다.
  3. 계층적구조 : 이러한 방식으로 층을 하나씩 쌓아감으로써 신경망은 계층적인 구조를 형성하게 됩니다. 각 층은 이전층에서 학습된 표현을 이용하여 더 추상화된 표현을 학습하고, 이를 통해 더 복잡한 데이터 패턴과 표현을 파악할 수 있게 됩니다.
  4. 특징추출 :SDA를 통해 깊은 신경망을 학습하면 각 층에서는 데이터의 다양한 특징과 패턴을 학습할 수 있습니다. 이렇게 학습된 신경망은 복잡한 데이터의 의미 있는 표현을 추출하는 데 도움이 되며, 이러한 표현은 다양한 작업에 활용할 수 있습니다.
- 요약 :  Stacked Denoising Autoencoders는 여러 개의 노이즈 제거 오토인코더를 계층적으로 쌓아 올림으로써 깊은 신경망에서 의미 있는 표현을 학습하는 방법입니다. 각 층은 이전 층에서 학습된 표현을 이용하여 더 추상화된 표현을 학습하며, 이를 통해 복잡한 데이터의 특징을 추출하는 데 도움이 됩니다.

**3.Local Denoising Criterion** : 각 노이즈 제거 오토인코더에서, 입력 데이터에 노이즈를 추가한 후에 원래 데이터로 복원하는 것이 학습 목표입니다.
이를 통해 각 층은 주어진 입력 데이터의 특정한 부분(로컬 패턴)을 학습하게 됩니다. 예를 들어, 얼굴 이미지에서 눈, 코, 입 등의 특징을 학습하는 것과 유사한 방식입니다.

**4.효과적인 표현 학습**: Stacked Denoising Autoencoders는 깊은 신경망에서 더 의미 있는 표현을 학습하는데 도움이 됩니다.
이전 층에서 학습된 표현을 활용하여 점진적으로 데이터의 추상화된 특성을 학습하게 되므로, 깊은 신경망에서 높은 수준의 의미 있는 특징을 추출할 수 있게 됩니다.
이는 다양한 데이터 분야에서 특히 복잡한 패턴과 표현을 학습하는데 유용합니다.

이 논문에서 제시된 Stacked Denoising Autoencoders는 깊은 신경망을 효과적으로 학습하는 방법을 제시하며, 이후 딥러닝 분야에서 중요한 역할을 한 중요한 아이디어 중 하나로 평가됩니다.
