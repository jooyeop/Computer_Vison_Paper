**논문요약**

변분 베이즈(Variational Bayes) 방법을 오토인코더와 결합하여 생성모델을 개선하는 기법을 제안하는 내용을 다룹니다.
이 논문은 주로 생성 모델링과 확률적 추론 분야에서 활용되며, 딥러닝 기반의 확률적인 방법론을 소개하는 중요한 작품입니다.

**1.** 오토인코더를 활용한 생성 모델링과 확률적 추론 방법의 결합을 제안 : 이를 "Variational Autoencoder" (VAE)라고 부릅니다.
**2.** VAE는 데이터의 생성 및 인코딩 과정을 확률 분포를 통해 모델링하고, 생성된 데이터가 주어진 상황에서 잠재 변수를 추론하는 방식으로 동작
**3.** VAE의 주요 아이디어는 잠재 변수의 사전 분포와 잠재 변수의 후포 분포를 정규 분포로 가정하고, 변분 베이즈의 개념을 활용하여 모델을 학습하는 것
**4.** 변분 베이즈를 통해 모델을 학습하고 샘플링을 통해 잠재 변수를 생성하며, 생성된 데이터와 원본 데이터 간의 차이를 최소화하는 방식으로 학습됩니다.

이 논문은 오토인코더와 확률적 추론의 결합을 통해 생성 모델을 개선하고 다양한 응용 분야에서 활용되는 중요한 아이디어를 제시한 것으로 평가받고 있습니다.
VAE는 이미지 생성, 데이터 임베딩, 생성적 모델링, 특징 학습 등 다양한 분야에서 사용되며, 더 일반적으로는 확률적 데이터 모델링과 딥러닝을 결합한 기법의 선구자적인 논문 중 하나입니다.

참고 논문 리뷰 : https://taeu.github.io/paper/deeplearning-paper-vae/

[1] VAE는 Generative Model 이다.
- Generative Model 이란 Traning data가 주어졌을 때 이 training data가 가지는 real분포와 같은 분포에서 sampling된 값으로 new data를 생성하는 model을 말한다.
  1. 훈련데이터분석 : Generative Model은 먼저 주어진 훈련 데이터를 분석하고 이 데이터의 분포를 파악합니다.
  2. 새로운 데이터 생성 : 학습된 분포 정보를 활용하여 모델은 새로운 데이터를 생성할 수 있습니다. 이 새로운 데이터는 훈련 데이터와 유사한 특성을 가지며, 새로운 데이터를 생성하는 과정은 모델일 학습한 데이터의 통계적 특성을 따라가는 것을 목표로 함
  3. 확률 분포 모델링 : Geterative Model은 데이터의 분포를 확률적으로 모델링하는 방식을 사용합니다. 이를 통해 데이터의 변동성이나 불확실성을 고려하여 새로운 데이터를 생성할 수 있습니다.
 
- 요약 : VAE(Variational Autoencoder) 역시 Generative Model의 한 종류로서, 주어진 데이터의 분포를 모델링하고, 훈련 데이터에서 학습한 분포 정보를 활용하여 잠재 변수를 생성하고, 이를 통해 새로운 데이터를 생성하는 기능을 가집니다.
  VAE의 장점 중 하나는 데이터 생성 과정에서 잠재 변수를 통해 데이터의 다양성과 불확실성을 조절할 수 있다는 점입니다.
  이를 통해 VAE는 이미지, 음성, 텍스트 등 다양한 데이터 유형에 대한 생성 모델로 활용되며, 다양한 응용 분야에서 활용됩니다.

[2] 확률 통계 이론 (Bayseain, conditional prob, pdf etc)
- 베이지안 확률(Bayesian probability): 세상에 반복할 수 없는 혹은 알 수 없는 확률들, 즉 일어나지 않은 일에 대한 확률을 사건과 관련이 있는 여러 확률들을 이용해 우리가 알고싶은 사건을 추정하는 것이 베이지안 확률이다.
  1. 이미 알려진 확률을 바탕으로 알고 싶은 사건의 확률을 추정하는 방법, 아직 발생하지 않은 사건에 대한 확률을 추론하기 위해 사용됩니다.
 
[3] 관련 용어
- latent : '잠재하는', '숨어있는', 'hidden'의 뜻을 가진 단어. 여기서 말하는 latent variable z는 특징(feature)을 가진 vector로 이해하면 좋다.
- intractable : 문제를 해결하기 ㅇ위해 필요한 시간이 문제의 크기에 따라 지수적(exponential) 증가한다면 그 문제는 난해(intractable)하다고 한다.
- explicit density model : 샘플링 모델의 구조(분포)를 명확히 정의
- implicit density model : 샘플링 모델의 구조(분폴)를 explicit하게 정의하지 않음
- density estimation : x라는 데이터만 관찰할 수 있을 때, 관찰할 수 없는 x가 샘플된 확률밀도함수(probability density function)을 estimate하는 것
- Gaussian distribution : 정규분포
- Bernoulli distribution : 베르누이분포
- Marginal Probability : 주변 확률 분포
- D_kl : 쿨백-라이블러 발산, 두 확률분포의 차이
- Encode/Decode : 암호화, 부호화 / 암호화해제, 부호화해제
- likelihood : 가능도

[4] (번외) Auto-Encoder
- VAE와 오토인코더는 목적이 전혀 다르다
- 오토인코더의 목적은 어떤 데이터를 잘 압축하는 것, 어떤 데이터의 특징을 잘 뽑는 것, 어떤 데이터의 차원을 잘 줄이는 것이다.
- 반면 VAE의 목적은 Generative model로 어떤 새로운 X를 만들어 내는 것이다.

### VAE
기존의 논문의 흐름은 Generative Model이 가지는 문제점들을 해소하기 위해 어떤 방식을 도입했는지 차례차례 설명하고 있다.
하지만 관련된 수식도 많고 중간에 생략된 식도 많아 논문대로 따라가다보면 전체적인 구조를 이해하기 힘들기 때문에 먼저 구조를 살펴본 뒤 각 구조가 가지는 의미가 무엇인지 살펴보고 최종적으로 정리하도록한다.

### VAE GOAL

![image](https://github.com/jooyeop/Computer_Vison_Paper/assets/97720878/1e939b88-ae9c-4307-8c53-9c02f0f41288)

VAE의 목표는 Generative Model의 목표와 같다.
  1. data와 같은 분포를 가지는 sample 분포에서 sample을 뽑은 이후
  2. 어떤 새로운 것을 생성해내는 것이 목표
1. 주어진 training data가 p_data(x)(확률밀도함수)가 어떤 분포를 가지고 있다면, sample모델 p_model(x) 역시 같은 분포를 가지면서 (sampling 부분)
2. 그 모델을 통해 나온 inference 값이 새로운 x라는 데이터이길 바란다.(Generate 부분)
  - ex) 몇 개의 다이아몬드(training data)를 가지고 있다고 생각해 봤을 때 training 다이아몬드 뿐만 아니라 모든 다이아몬드의 확률분포와 똑같은 분포를 가진 모델에서 값을 뽑아 (1.smapling) training을 시켰던 다이아몬드와는 다른 또 다른 다이아몬드를 만드는것

### VAE 구조

![image](https://github.com/jooyeop/Computer_Vison_Paper/assets/97720878/73cbe276-8463-419b-b9ab-bab0c2178846)

VAE 구조를 완벽히 정리한 그림
### 1. Encoder
- input: x –> 𝑞_∅ (𝑥)–> 𝜇_𝑖,𝜎_𝑖

![image](https://github.com/jooyeop/Computer_Vison_Paper/assets/97720878/c2da046d-672f-4edb-9ba7-e1ed9f1430ca)

```
img_shape = (28,28,1)
batch_size = 16
latent_dim = 2

input_img = keras.Input(shape = img_shape)
x = layers.Conv2D(32,3,padding='same',activation='relu')(input_img)
x = layers.Conv2D(64,3,padding='same',activation='relu',strides=(2,2))(x)
x = layers.Conv2D(64,3,padding='same',activation='relu')(x)
x = layers.Conv2D(64,3,padding='same',activation='relu')(x)

shape_before_flattening = K.int_shape(x) # return tuple of integers of shape of x

x = layers.Flatten()(x)
x = layers.Dense(32,activation='relu')(x)

z_mean = layers.Dense(latent_dim)(x)
z_log_var = layers.Dense(latent_dim)(x)
```
- Input shape(x) : (28, 28, 1)
- 𝑞_∅ (𝑥) 는 encoder 함수인데, x가 주어졌을때(given) z값의 분포의 평균과 분산을 아웃풋으로 내는 함수이다.
- 다시말해 q 함수(=Encoder)의 output은 𝜇_𝑖,𝜎_𝑖 이다.
어떤 X라는 입력을 넣은 인코더의 아웃풋은 𝜇_𝑖,𝜎_𝑖 이다. 어떤 데이터의 특징을(latent variable) X를 통해 추측한다.
기본적으로 여기서 나온 특징들의 분포는 정규분포를 따른다고 가정한다.
이런 특징들이 가지는 확률 분포  𝑞_∅ (𝑥) (정확히 말하면 $의 true 분포 (= $)를 정규분포(=Gaussian)라 가정한다는 말이다.
따라서 latent space의 latent variable 값들은 𝑞_∅ (𝑥)의 true 분포를 approximate하는 𝜇_𝑖,𝜎_𝑖를 나타낸다.

- 요약 : 변분 오토인코더의 인코더 부분을 정의한 코드, VAE는 기본적으로 입력데이터를 잠재공간(latent space)에 표현하고, 이 잠재공간에서 다시 원래의 입력 데이터를 복구하려고 하는구조
  1. 잠재변수(Latent Variable) : VAE에서, 잠재 변수는 데이터의 내재적인 특징을 표현하는 변수 입니다. 예를 들어, 얼굴 사진 데이터를 다룰 때, 잠재 변수는 얼굴의 특징(예시 : 눈의 크기, 코 모양 등)을 표현할 수 있습니다.
  2. 𝑞_∅ (𝑥) (Encoder): 이 함수는 입력 데이터 x를 받아서, 해당 데이터가 잠재 공간에서 어떤 위치(분포)에 있을지를 표현하는 두 가지 값, 𝜇_𝑖(평균)와 𝜎_𝑖(분산)을 반환합니다.
  3. 정규 분포 (Gaussian Distribution): 여기서, 잠재 공간의 각 위치는 정규 분포를 가정합니다. 즉, 각 데이터 포인트 x에 대해, 그 데이터의 잠재 특징은 평균 𝜇_𝑖와 분산 𝜎_𝑖의 정규 분포를 따른다고 가정하는 것입니다.
     - 간단히 말하면, 이 인코더는 입력 이미지(예 : 28 x 28 크기의 이미지)를 받아 그 임지ㅣ의 내재적 특징을 잠재 공간에서의 위치(평균과 분산)로 변환하는 역할
     - 그리고 이 위치는 정규분포를 가정하므로, VAE는 이 분포를 사용하여 새로운 데이터 포인트를 생성할 수 있습니다.


### 2. Reparameterization Trick(Sampling)

![image](https://github.com/jooyeop/Computer_Vison_Paper/assets/97720878/61fb74e9-e7f6-49b1-8c4a-2bcf4a3f3c47)

```
def sampling(args):
    z_mean, z_log_var = args
    epsilon = K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0., stddev=1.)
    return z_mean + K.exp(z_log_var) * epsilon

z = layers.Lambda(sampling)([z_mean, z_log_var])
```
만약 Encoder 결과에서 나온 값을 활용해 decoding 하는데 sampling 하지 않는다면 어떤 일이 벌어질까? 당연히 는 한 값을 가지므로 그에 대한 decoder(NN)역시 한 값만 뱉는다.
그렇게 된다면 어떤 한 variable은 무조건 똑같은 한 값의 output을 가지게 된다.

하지만 Generative Model, VAE가 하고 싶은 것은, 어떤 data의 true 분포가 있으면 그 분포에서 하나를 뽑아 기존 DB에 있지 않은 새로운 data를 생성하고 싶다.
따라서 우리는 필연적으로 그 데이터의 확률분포와 같은 분포에서 하나를 뽑는 sampling을 해야한다. 하지만 그냥 sampling 한다면 sampling 한 값들을 backpropagation 할 수 없다.
(아래의 그림을 보면 직관적으로 이해할 수 있다) 이를 해결하기 위해 reparmeterization trick을 사용한다.

![image](https://github.com/jooyeop/Computer_Vison_Paper/assets/97720878/916b45a6-90d1-45df-a97f-e8e651ea0234)

정규분포에서 z1를 샘플링하는 것이나, 입실론을 정규분포(자세히는 N(0,1))에서 샘플링하고 그 값을 분산과 곱하고 평균을 더해 z2를 만들거나 두 z1,z2 는 같은 분포를 가지기 때문이다.
그래서 코드에서 epsilon을 먼저 정규분포에서 random하게 뽑고, 그 epsilon을 exp(z_log_var)과 곱하고 z_mean을 더한다.
그렇게 형성된 값이 z가 된다.

- 요약 : Reparameterization Trick은 샘플링 과정을 미분 가능하게 바꿔주는 기법입니다. 샘플링을 그대로 하면 역전파가 안 되기 때문에, 샘플링 과정을 조금 바꾸어 미분 가능하게 만듭니다.
  - Encoder가 생성한 'z_mean'과 'z_log_var'를 사용하지 않고, 따로 랜덤한 노이즈 'epsilon'을 생성
  - 이 epsilon은 표준 정규분포에서 뽑힌 값
  - 그 다음 'z_mean'과 'exp(z_log_var)'에 이 노이즈를 연산하여 최종적인 'z'값을 생성
    - 이렇게하면 'z'의 생성과정에 미분 불가능한 부분이 없어져서, 전체 네트워크를 통해 역전파를 할 수 있습니다.
    - 즉, 샘플링을 통해서도 기울기를 전달할 수 있게 됩니다.
- 결론 : 만약 트릭을 사용하지 않고, Encoder가 생성한 'z_mean'또는 'z_log_var'을 그대로 사용한다면, 모델이 단순히 데이터를 잘 복제하는 방향으로 학습될 것임
  - 즉, 생성모델의 목적에 맞지 않게 되기에 Reparameterization Trick은 이 문제를 해결해줍니다.

### 3. Decoder

![image](https://github.com/jooyeop/Computer_Vison_Paper/assets/97720878/a2d00862-a491-4cbd-91c0-20ca8bf7a517)

```
## 8.25 VAE decoder network, mapping latent space points to imgaes

decoder_input = layers.Input(K.int_shape(z)[1:])
x = layers.Dense(np.prod(shape_before_flattening[1:]),activation='relu')(decoder_input)
x = layers.Reshape(shape_before_flattening[1:])(x)
x = layers.Conv2DTranspose(32,3,padding='same',activation='relu',strides=(2,2))(x)
x = layers.Conv2D(1,3,padding='same',activation='sigmoid')(x)

decoder = Model(decoder_input, x)
z_decoded = decoder(z)
```

z 값을 g 함수(decoder)에 넣고 deconv(코드에서는 Conv2DTranspose)를 해 원래 이미지 사이즈의 아웃풋 z_decoded가 나오게 된다.
이때 p_data(x)의 분포를 Bernoulli 로 가정했으므로(이미지 recognition 에서 Gaussian 으로 가정할때보다 Bernoulli로 가정해야 의미상 그리고 결과상 더 적절했기 때문) output 값은 0~1 사이 값을 가져야하고, 이를 위해 activatino function을 sigmoid로 설정해주었다. (Gaussian 분포를 따른다고 가정하고 푼다면 아래 loss를 다르게 설정해야한다.)


### 4. VAE 학습

Loss Fucntion 이해
Loss 는 크게 총 2가지 부분이 있다.

![image](https://github.com/jooyeop/Computer_Vison_Paper/assets/97720878/e412cb35-438d-414d-b4f2-41ffa447deb7)

```
 def vae_loss(self, x, z_decoded):
        x = K.flatten(x)
        z_decoded = K.flatten(z_decoded)
        xent_loss = keras.metrics.binary_crossentropy(x,z_decoded)
        kl_loss   = -5e-4*K.mean(1+z_log_var-K.square(z_mean)-K.exp(z_log_var),axis=-1)
        return K.mean(xent_loss + kl_loss)

```

Reconstruction Loss(code에서는 xent_loss)
Regularization Loss(code에서는 kl_loss)
일단 직관적으로 이해를 하자면,

Generative 모델답게 새로운 X를 만들어야하므로 X와 만들어진 output, New X와의 관계를 살펴봐야하고, 이를 Reconstruction Loss 부분이라고 한다. 이때 디코더 부분의 pdf는 Bernoulli 분포를 따른다고 가정했으므로 그 둘간의 cross entropy를 구한다

X가 원래 가지는 분포와 동일한 분포를 가지게 학습하게 하기위해 true 분포를 approximate 한 함수의 분포에 대한 loss term이 Regularization Loss다.
이때 loss는 true pdf 와 approximated pdf간의 D_kl(두 확률분포의 차이(거리))을 계산한다.


























